{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "28c3a211",
   "metadata": {},
   "source": [
    "# Prototyping and Testing the execution of the verifiers on the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7033488",
   "metadata": {},
   "source": [
    "#### Some config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ca7f653d",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_PROC = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166a0484",
   "metadata": {},
   "source": [
    "## Execution Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c3ccd467",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/creux/Documents/AI/VIFagent/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\u001b[32m2025-11-03 16:31:43.772\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mvif.utils.caching\u001b[0m:\u001b[36minstantiate_cache\u001b[0m:\u001b[36m26\u001b[0m - \u001b[1mseg_cache cache loaded\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from vif.baselines.models import VerEvaluation\n",
    "from vif.baselines.verifiers_baseline.ver_baseline import TexVerBaseline\n",
    "from datasets.formatting.formatting import LazyBatch\n",
    "from PIL import Image\n",
    "import sys\n",
    "from datasets import load_dataset, Dataset\n",
    "from loguru import logger\n",
    "\n",
    "from vif.utils.renderer.tex_renderer import TexRenderer\n",
    "\n",
    "renderer = TexRenderer()\n",
    "\n",
    "\n",
    "def execute_verifier_on_dataset(verifier: TexVerBaseline, dataset: Dataset, n=1):\n",
    "    def exec_verif(row: LazyBatch,indice:int):\n",
    "        metadata = verifier.get_config_metadata()\n",
    "        ver_eval_input: VerEvaluation = VerEvaluation(\n",
    "            id=row[\"id\"][0],\n",
    "            approach_name=metadata[\"name\"],\n",
    "            config_metadata=metadata,\n",
    "            initial_code=row[\"code\"][0],\n",
    "            initial_image=row[\"original_image\"][0],\n",
    "            initial_instruction=row[\"instruction\"][0],\n",
    "            initial_solution=row[\"solution\"][0],\n",
    "            initial_solution_image=row[\"solution_image\"][0],\n",
    "            expected=row[\"expected\"][0],\n",
    "        )\n",
    "        results: list[VerEvaluation] = []\n",
    "        for _ in range(n):            \n",
    "            res = verifier.assess_customization(ver_eval_input)\n",
    "            \n",
    "            results.append(res)\n",
    "\n",
    "        new_rows = defaultdict(list)\n",
    "        for i, ver_result in enumerate(results):\n",
    "            res_dict = ver_result.model_dump()\n",
    "            for key, value in res_dict.items():\n",
    "                new_rows[key].append(value)\n",
    "            new_rows[\"try\"].append(i)\n",
    "            new_rows[\"index\"].append(indice[0])\n",
    "        return new_rows\n",
    "\n",
    "    return dataset.map(\n",
    "        exec_verif,\n",
    "        num_proc=NUM_PROC,\n",
    "        batched=True,\n",
    "        batch_size=1,\n",
    "        remove_columns=dataset.column_names,\n",
    "        with_indices=True,\n",
    "    )\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87135b92",
   "metadata": {},
   "source": [
    "## Execution of the verifiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "558fef03",
   "metadata": {},
   "source": [
    "#### Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6211061b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import os\n",
    "from google import genai\n",
    "from google.genai import types as genTypes\n",
    "from vif.baselines.verifiers_baseline import (\n",
    "    FalconVerifier,\n",
    "    TextVerifier,\n",
    "    TextVisualVerifier,\n",
    "    ViperGPTVerifier,\n",
    "    VisualPropertiesVerifier,\n",
    "    VisualVerifier,\n",
    "    VisualCodeVerifier,\n",
    ")\n",
    "\n",
    "\n",
    "client = openai.Client(\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    api_key=os.environ.get(\"OPENROUTER_API_KEY\"),\n",
    ")\n",
    "\n",
    "gclient = genai.Client(\n",
    "        api_key=os.environ.get(\"GOOGLE_API_KEY\"),\n",
    "        http_options=genTypes.HttpOptions(api_version=\"v1alpha\"),\n",
    "    )\n",
    "\n",
    "logger.configure(handlers=[{\"sink\": sys.stdout, \"level\": \"WARNING\"}])\n",
    "ds = load_dataset(\"CharlyR/VeriTikz\", \"full\", split=\"train\")\n",
    "ds =ds.select(range(0,2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970b0c77",
   "metadata": {},
   "source": [
    "#### Text Verifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ffd700e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 25/25 [04:40<00:00, 11.22s/ examples]\n"
     ]
    }
   ],
   "source": [
    "text_verifier: TexVerBaseline = TextVerifier(\n",
    "    model=\"qwen/qwen3-vl-32b-instruct\", temperature=0.5, client=client\n",
    ")\n",
    "\n",
    "verifier_text_ds = execute_verifier_on_dataset(text_verifier, ds, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a2d11a",
   "metadata": {},
   "source": [
    "#### Visual Verifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54e8e052",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 25/25 [01:58<00:00,  4.74s/ examples]\n"
     ]
    }
   ],
   "source": [
    "visual_verifier: TexVerBaseline = VisualVerifier(\n",
    "    model=\"qwen/qwen3-vl-32b-instruct\",\n",
    "    temperature=0.5,\n",
    "    client=client\n",
    ")\n",
    "\n",
    "verifier_visual_ds = execute_verifier_on_dataset(visual_verifier,ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d638412",
   "metadata": {},
   "source": [
    "#### Text/Visual Verifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7f6eac81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 25/25 [03:53<00:00,  9.32s/ examples]\n"
     ]
    }
   ],
   "source": [
    "text_visual_verifier: TexVerBaseline = TextVisualVerifier(\n",
    "    model=\"qwen/qwen3-vl-32b-instruct\",\n",
    "    temperature=0.5,\n",
    "    client=client\n",
    ")\n",
    "\n",
    "verifier_text_visual_ds = execute_verifier_on_dataset(text_visual_verifier,ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81044702",
   "metadata": {},
   "source": [
    "#### Visual Verifier with code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6843c721",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function execute_verifier_on_dataset.<locals>.exec_verif at 0x7f379f6a8900> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n",
      "Map: 100%|██████████| 2/2 [01:43<00:00, 51.95s/ examples]\n"
     ]
    }
   ],
   "source": [
    "text_visual_code_verifier: TexVerBaseline = VisualCodeVerifier(\n",
    "    model=\"openai/gpt-5-mini\",\n",
    "    temperature=0.5,\n",
    "    client=client\n",
    ")\n",
    "\n",
    "verifier_visual_code_ds = execute_verifier_on_dataset(text_visual_code_verifier,ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7baf75",
   "metadata": {},
   "source": [
    "#### Visual Property Verifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a559b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "visual_property_verifier: TexVerBaseline = VisualPropertiesVerifier(\n",
    "    model=\"qwen/qwen3-vl-32b-instruct\",\n",
    "    temperature=0.5,\n",
    "    client=client\n",
    ")\n",
    "\n",
    "verifier_visual_property_ds = execute_verifier_on_dataset(visual_property_verifier,ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110ab1e4",
   "metadata": {},
   "source": [
    "#### ViperGPT Verifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18db230c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#full config available here in config file vif/baselines/verifiers_baseline/ViperGPT_adapt/ViperGPT_config.py\n",
    "visual_property_verifier: TexVerBaseline = ViperGPTVerifier(\n",
    "    model=\"qwen/qwen3-vl-32b-instruct\",\n",
    "    temperature=0.5,\n",
    "    client=client\n",
    ")\n",
    "\n",
    "verifier_vipergpt_ds = execute_verifier_on_dataset(visual_property_verifier,ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c630a5",
   "metadata": {},
   "source": [
    "#### Ours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f2b8d55",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "FalconVerifier.__init__() missing 1 required keyword-only argument: 'oracle_gen_model_temperature'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m falcon_verifier: TexVerBaseline = \u001b[43mFalconVerifier\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43moracle_gen_model\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mqwen/qwen3-vl-32b-instruct\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvision_model\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgemini-2.5-flash\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproperty_model\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mqwen/qwen3-vl-32b-instruct\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[43mproperty_model_temperature\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgclient\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgclient\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43moclient\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclient\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m verifier_falcon_ds = ds.map(execute_verifier_on_dataset(falcon_verifier,ds))\n",
      "\u001b[31mTypeError\u001b[39m: FalconVerifier.__init__() missing 1 required keyword-only argument: 'oracle_gen_model_temperature'"
     ]
    }
   ],
   "source": [
    "falcon_verifier: TexVerBaseline = FalconVerifier(\n",
    "    oracle_gen_model=\"qwen/qwen3-vl-32b-instruct\",\n",
    "    oracle_gen_model_temperature=0.5,\n",
    "    vision_model=\"gemini-2.5-flash\",\n",
    "    property_model=\"qwen/qwen3-vl-32b-instruct\",\n",
    "    property_model_temperature=0.5,\n",
    "    gclient=gclient,\n",
    "    oclient=client\n",
    ")\n",
    "\n",
    "verifier_falcon_ds =execute_verifier_on_dataset(falcon_verifier,ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a3086b",
   "metadata": {},
   "source": [
    "### Concat and save data locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c93f9a23",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'verifier_text_ds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Dataset,concatenate_datasets\n\u001b[32m      2\u001b[39m dss = [\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     \u001b[43mverifier_text_ds\u001b[49m,\n\u001b[32m      4\u001b[39m     verifier_visual_ds,\n\u001b[32m      5\u001b[39m     verifier_text_visual_ds,\n\u001b[32m      6\u001b[39m     verifier_visual_code_ds,\n\u001b[32m      7\u001b[39m     \u001b[38;5;66;03m#verifier_visual_property_ds,\u001b[39;00m\n\u001b[32m      8\u001b[39m     \u001b[38;5;66;03m#verifier_vipergpt_ds,\u001b[39;00m\n\u001b[32m      9\u001b[39m     \u001b[38;5;66;03m#verifier_falcon_ds,\u001b[39;00m\n\u001b[32m     10\u001b[39m ]\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtime\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m gmtime, strftime\n\u001b[32m     13\u001b[39m cur_time = strftime(\u001b[33m\"\u001b[39m\u001b[33m%\u001b[39m\u001b[33mY-\u001b[39m\u001b[33m%\u001b[39m\u001b[33mm-\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m-\u001b[39m\u001b[33m%\u001b[39m\u001b[33mH-ds_conc\u001b[39m\u001b[33m\"\u001b[39m, gmtime())\n",
      "\u001b[31mNameError\u001b[39m: name 'verifier_text_ds' is not defined"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset,concatenate_datasets\n",
    "dss = [\n",
    "    verifier_text_ds,\n",
    "    verifier_visual_ds,\n",
    "    verifier_text_visual_ds,\n",
    "    verifier_visual_code_ds,\n",
    "    #verifier_visual_property_ds,\n",
    "    #verifier_vipergpt_ds,\n",
    "    #verifier_falcon_ds,\n",
    "]\n",
    "\n",
    "from time import gmtime, strftime\n",
    "cur_time = strftime(\"%Y-%m-%d-%H-ds_conc\", gmtime())\n",
    "conc_dss:Dataset = concatenate_datasets(dss)\n",
    "conc_dss.save_to_disk(f\"notebooks/verifier_execution/{cur_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af31c7e",
   "metadata": {},
   "source": [
    "### Debugging code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ebb4bbc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n    \"code\": \"import cv2\\\\nimport numpy as np\\\\nfrom math import atan2, degrees\\\\n\\\\ndef verify_customization(initial_image, customized_image):\\\\n    # Helper to find small L-shaped axis origin by detecting short perpendicular line intersections\\\\n    def find_origin(img):\\\\n        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\\\\n        # Resize for speed if very large\\\\n        h0, w0 = gray.shape[:2]\\\\n        scale = 1.0\\\\n        if max(h0, w0) > 1000:\\\\n            scale = 1000.0 / max(h0, w0)\\\\n            gray = cv2.resize(gray, (int(w0*scale), int(h0*scale)), interpolation=cv2.INTER_AREA)\\\\n        h, w = gray.shape[:2]\\\\n        edges = cv2.Canny(gray, 50, 150, apertureSize=3)\\\\n        # Dilate a bit to join small segments\\\\n        kernel = np.ones((2,2), np.uint8)\\\\n        edges = cv2.dilate(edges, kernel, iterations=1)\\\\n        # Hough probabilistic\\\\n        lines = cv2.HoughLinesP(edges, rho=1, theta=np.pi/180, threshold=30, minLineLength=10, maxLineGap=10)\\\\n        if lines is None:\\\\n            return None\\\\n        lines = lines.reshape(-1,4)\\\\n        # Convert lines to (x1,y1,x2,y2)\\\\n        # For each pair, compute intersection if within segments\\\\n        candidates = []\\\\n        for i in range(len(lines)):\\\\n            x1,y1,x2,y2 = lines[i]\\\\n            dx1 = x2-x1; dy1 = y2-y1\\\\n            len1 = np.hypot(dx1, dy1)\\\\n            for j in range(i+1, len(lines)):\\\\n                x3,y3,x4,y4 = lines[j]\\\\n                dx2 = x4-x3; dy2 = y4-y3\\\\n                len2 = np.hypot(dx2, dy2)\\\\n                # angle between\\\\n                ang1 = atan2(dy1, dx1)\\\\n                ang2 = atan2(dy2, dx2)\\\\n                angdeg = abs(degrees(ang1 - ang2))\\\\n                angdeg = angdeg % 180\\\\n                if angdeg > 90:\\\\n                    angdeg = 180 - angdeg\\\\n                # check near perpendicular\\\\n                if abs(angdeg - 90) > 20:\\\\n                    continue\\\\n                # compute intersection of infinite lines\\\\n                denom = (dx1*dy2 - dy1*dx2)\\\\n                if abs(denom) < 1e-6:\\\\n                    continue\\\\n                # Solve for intersection\\\\n                # Using line-line intersection formula\\\\n                # Line1: (x1,y1)+t*(dx1,dy1), Line2: (x3,y3)+u*(dx2,dy2)\\\\n                t = ((x3 - x1)*dy2 - (y3 - y1)*dx2) / denom\\\\n                u = ((x3 - x1)*dy1 - (y3 - y1)*dx1) / denom\\\\n                # check intersection lies within segment bounds (allow small margin)\\\\n                if t < -0.2 or t > 1.2 or u < -0.2 or u > 1.2:\\\\n                    continue\\\\n                ix = x1 + t*dx1\\\\n                iy = y1 + t*dy1\\\\n                # We are looking for small L-shapes: both lengths relatively short\\\\n                # Use scaled lengths\\\\n                if len1 < max(w,h)*0.7 and len2 < max(w,h)*0.7:\\\\n                    # Score: smaller average length is better\\\\n                    score = (len1 + len2)/2.0\\\\n                    candidates.append((score, ix/scale, iy/scale))\\\\n        if not candidates:\\\\n            return None\\\\n        # choose candidate with smallest average segment length (likely the small axis marker)\\\\n        candidates.sort(key=lambda x: x[0])\\\\n        _, x_best, y_best = candidates[0]\\\\n        return (float(x_best), float(y_best))\\\\n\\\\n    o1 = find_origin(initial_image)\\\\n    o2 = find_origin(customized_image)\\\\n    result = {\\\\n        \\'origin_initial\\': o1,\\\\n        \\'origin_customized\\': o2,\\\\n        \\'moved\\': False,\\\\n        \\'reason\\': \\'\\'\\\\n    }\\\\n    if o1 is None or o2 is None:\\\\n        result[\\'reason\\'] = \\'Could not locate origin in one or both images.\\'\\\\n        return result\\\\n    x1,y1 = o1\\\\n    x2,y2 = o2\\\\n    h,w = initial_image.shape[:2]\\\\n    # Determine movement\\\\n    dx = x2 - x1\\\\n    dy = y2 - y1\\\\n    dist = np.hypot(dx, dy)\\\\n    result[\\'dx\\'] = dx; result[\\'dy\\'] = dy; result[\\'dist\\'] = dist\\\\n    # Heuristic: moved significantly to the right and upward into central region\\\\n    # Check if moved more than 8% of width\\\\n    if abs(dx) > 0.08*w or abs(dy) > 0.06*h:\\\\n        result[\\'moved\\'] = True\\\\n    else:\\\\n        result[\\'reason\\'] = \\'Movement too small.\\'\\\\n    return result\\\\n\\\\n# If initial_image and customized_image are present in the environment, run verification and return result\\\\ntry:\\\\n    res = verify_customization(initial_image, customized_image)\\\\nexcept Exception as e:\\\\n    res = {\\'error\\': str(e)}\\\\nres\\\\n\",\\n    \"name\": \"CodeExecException\",\\n    \"wrapped_exception\": \"OpenCV(4.11.0) :-1: error: (-5:Bad argument) in function \\'cvtColor\\'\\\\n> Overload resolution failed:\\\\n>  - src is not a numpy array, neither a scalar\\\\n>  - Expected Ptr<cv::UMat> for argument \\'src\\'\\\\n\"\\n}'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "loaded_wrapped = json.loads(verifier_visual_code_ds[\"errors\"][0][\"final_request\"][0])\n",
    "json.dumps(loaded_wrapped, indent=4, sort_keys=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc15ae02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "import cv2\n",
      "import numpy as np\n",
      "from math import atan2, degrees\n",
      "\n",
      "def verify_customization(initial_image, customized_image):\n",
      "    # Helper to find small L-shaped axis origin by detecting short perpendicular line intersections\n",
      "    def find_origin(img):\n",
      "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
      "        # Resize for speed if very large\n",
      "        h0, w0 = gray.shape[:2]\n",
      "        scale = 1.0\n",
      "        if max(h0, w0) > 1000:\n",
      "            scale = 1000.0 / max(h0, w0)\n",
      "            gray = cv2.resize(gray, (int(w0*scale), int(h0*scale)), interpolation=cv2.INTER_AREA)\n",
      "        h, w = gray.shape[:2]\n",
      "        edges = cv2.Canny(gray, 50, 150, apertureSize=3)\n",
      "        # Dilate a bit to join small segments\n",
      "        kernel = np.ones((2,2), np.uint8)\n",
      "        edges = cv2.dilate(edges, kernel, iterations=1)\n",
      "        # Hough probabilistic\n",
      "        lines = cv2.HoughLinesP(edges, rho=1, theta=np.pi/180, threshold=30, minLineLength=10, maxLineGap=10)\n",
      "        if lines is None:\n",
      "            return None\n",
      "        lines = lines.reshape(-1,4)\n",
      "        # Convert lines to (x1,y1,x2,y2)\n",
      "        # For each pair, compute intersection if within segments\n",
      "        candidates = []\n",
      "        for i in range(len(lines)):\n",
      "            x1,y1,x2,y2 = lines[i]\n",
      "            dx1 = x2-x1; dy1 = y2-y1\n",
      "            len1 = np.hypot(dx1, dy1)\n",
      "            for j in range(i+1, len(lines)):\n",
      "                x3,y3,x4,y4 = lines[j]\n",
      "                dx2 = x4-x3; dy2 = y4-y3\n",
      "                len2 = np.hypot(dx2, dy2)\n",
      "                # angle between\n",
      "                ang1 = atan2(dy1, dx1)\n",
      "                ang2 = atan2(dy2, dx2)\n",
      "                angdeg = abs(degrees(ang1 - ang2))\n",
      "                angdeg = angdeg % 180\n",
      "                if angdeg > 90:\n",
      "                    angdeg = 180 - angdeg\n",
      "                # check near perpendicular\n",
      "                if abs(angdeg - 90) > 20:\n",
      "                    continue\n",
      "                # compute intersection of infinite lines\n",
      "                denom = (dx1*dy2 - dy1*dx2)\n",
      "                if abs(denom) < 1e-6:\n",
      "                    continue\n",
      "                # Solve for intersection\n",
      "                # Using line-line intersection formula\n",
      "                # Line1: (x1,y1)+t*(dx1,dy1), Line2: (x3,y3)+u*(dx2,dy2)\n",
      "                t = ((x3 - x1)*dy2 - (y3 - y1)*dx2) / denom\n",
      "                u = ((x3 - x1)*dy1 - (y3 - y1)*dx1) / denom\n",
      "                # check intersection lies within segment bounds (allow small margin)\n",
      "                if t < -0.2 or t > 1.2 or u < -0.2 or u > 1.2:\n",
      "                    continue\n",
      "                ix = x1 + t*dx1\n",
      "                iy = y1 + t*dy1\n",
      "                # We are looking for small L-shapes: both lengths relatively short\n",
      "                # Use scaled lengths\n",
      "                if len1 < max(w,h)*0.7 and len2 < max(w,h)*0.7:\n",
      "                    # Score: smaller average length is better\n",
      "                    score = (len1 + len2)/2.0\n",
      "                    candidates.append((score, ix/scale, iy/scale))\n",
      "        if not candidates:\n",
      "            return None\n",
      "        # choose candidate with smallest average segment length (likely the small axis marker)\n",
      "        candidates.sort(key=lambda x: x[0])\n",
      "        _, x_best, y_best = candidates[0]\n",
      "        return (float(x_best), float(y_best))\n",
      "\n",
      "    o1 = find_origin(initial_image)\n",
      "    o2 = find_origin(customized_image)\n",
      "    result = {\n",
      "        'origin_initial': o1,\n",
      "        'origin_customized': o2,\n",
      "        'moved': False,\n",
      "        'reason': ''\n",
      "    }\n",
      "    if o1 is None or o2 is None:\n",
      "        result['reason'] = 'Could not locate origin in one or both images.'\n",
      "        return result\n",
      "    x1,y1 = o1\n",
      "    x2,y2 = o2\n",
      "    h,w = initial_image.shape[:2]\n",
      "    # Determine movement\n",
      "    dx = x2 - x1\n",
      "    dy = y2 - y1\n",
      "    dist = np.hypot(dx, dy)\n",
      "    result['dx'] = dx; result['dy'] = dy; result['dist'] = dist\n",
      "    # Heuristic: moved significantly to the right and upward into central region\n",
      "    # Check if moved more than 8% of width\n",
      "    if abs(dx) > 0.08*w or abs(dy) > 0.06*h:\n",
      "        result['moved'] = True\n",
      "    else:\n",
      "        result['reason'] = 'Movement too small.'\n",
      "    return result\n",
      "\n",
      "# If initial_image and customized_image are present in the environment, run verification and return result\n",
      "try:\n",
      "    res = verify_customization(initial_image, customized_image)\n",
      "except Exception as e:\n",
      "    res = {'error': str(e)}\n",
      "res\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(loaded_wrapped[\"code\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "748d49b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenCV(4.11.0) :-1: error: (-5:Bad argument) in function 'cvtColor'\n",
      "> Overload resolution failed:\n",
      ">  - src is not a numpy array, neither a scalar\n",
      ">  - Expected Ptr<cv::UMat> for argument 'src'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(loaded_wrapped[\"wrapped_exception\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1ebfc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VIFagent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
