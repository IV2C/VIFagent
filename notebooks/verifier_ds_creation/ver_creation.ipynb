{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "41d609a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/creux/Documents/AI/VIFagent/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from datasets import load_dataset\n",
    "from loguru import logger\n",
    "\n",
    "logger.configure(handlers=[{\"sink\": sys.stdout, \"level\": \"WARNING\"}])\n",
    "ds = load_dataset(\"CharlyR/vtikz\", \"tikz\", split=\"benchmark\")\n",
    "ds = ds.select_columns([\"id\",\"type\",\"instruction\",\"code\",\"template_solution_code\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ade3fe",
   "metadata": {},
   "source": [
    "#### Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ded07c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets.formatting.formatting import LazyBatch\n",
    "from collections import defaultdict\n",
    "from notebooks.verifier_ds_creation.verifier_utils import (\n",
    "    correct_from_choices,\n",
    "    generate_all_incorrect_solutions,\n",
    "    handle_def,\n",
    "    correct_from_range,\n",
    "    correct_from_rangei,\n",
    ")\n",
    "\n",
    "def create_incorrect_solutions(row: LazyBatch):\n",
    "    all_created_template_codes: dict[str : list[str]] = defaultdict(list)\n",
    "    original_code = row[\"code\"][0]\n",
    "    ignored_row =[]\n",
    "    for template_code in row[\"template_solution_code\"]:\n",
    "        template_code = template_code[0]\n",
    "        all_created_template_codes[template_code],ignored = generate_all_incorrect_solutions(\n",
    "            original_code, template_code\n",
    "        )\n",
    "        ignored_row.append(ignored)\n",
    "\n",
    "    if all(ignored_row):\n",
    "        logger.warning(f\"{row['id']} is ignored.\")\n",
    "\n",
    "    new_rows = defaultdict(list)\n",
    "    for template, created_template_codes in all_created_template_codes.items():\n",
    "        for created_template_code in created_template_codes:\n",
    "            for existing_col in set(row.keys()):\n",
    "                new_rows[existing_col].append(row[existing_col][0])\n",
    "            new_rows[\"original_template\"].append(template)\n",
    "            new_rows[\"solution\"].append(created_template_code)\n",
    "            new_rows[\"expected\"].append(False)\n",
    "    if len(new_rows) == 0:\n",
    "        new_rows = {\n",
    "            \"original_template\": [],\n",
    "            \"solution\": [],\n",
    "            \"expected\": [],\n",
    "        }\n",
    "        for existing_col in set(row.keys()):\n",
    "            new_rows[existing_col] = []\n",
    "    return new_rows\n",
    "\n",
    "\n",
    "def create_correct_solutions(row: LazyBatch):\n",
    "    all_created_template_codes: dict[str : list[str]] = defaultdict(list)\n",
    "    for template_code in row[\"template_solution_code\"]:\n",
    "        template_code = template_code[\n",
    "            0\n",
    "        ]  # batch size always one, used for create more rows as output\n",
    "        new_template_codes = handle_def(template_code)\n",
    "        new_template_codes = [\n",
    "            fin_templ_code\n",
    "            for code in new_template_codes\n",
    "            for fin_templ_code in correct_from_range(code)\n",
    "        ]\n",
    "        new_template_codes = [\n",
    "            fin_templ_code\n",
    "            for code in new_template_codes\n",
    "            for fin_templ_code in correct_from_rangei(code)\n",
    "        ]\n",
    "        new_template_codes = [\n",
    "            fin_templ_code\n",
    "            for code in new_template_codes\n",
    "            for fin_templ_code in correct_from_choices(code)\n",
    "        ]\n",
    "        all_created_template_codes[template_code] = new_template_codes\n",
    "\n",
    "    new_rows = defaultdict(list)\n",
    "    for template, created_template_codes in all_created_template_codes.items():\n",
    "        for created_template_code in created_template_codes:\n",
    "            for existing_col in set(row.keys()):\n",
    "                new_rows[existing_col].append(row[existing_col][0])\n",
    "            new_rows[\"original_template\"].append(template)\n",
    "            new_rows[\"solution\"].append(created_template_code)\n",
    "            new_rows[\"expected\"].append(True)\n",
    "\n",
    "    return new_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e797f052",
   "metadata": {},
   "source": [
    "### Creating the dataset + filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb789371",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 100/100 [00:00<00:00, 513.18 examples/s]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#test_ds = Dataset.from_dict({\"template_solution_code\":[[test_code]]})\n",
    "\n",
    "#expanded_ds = test_ds.select([0]).map(create_solutions,batched=True,batch_size=1,load_from_cache_file=False)\n",
    "\n",
    "expanded_ds_cor = ds.map(create_correct_solutions,batched=True,batch_size=1,load_from_cache_file=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6adc60e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter 'function'=<function create_incorrect_solutions at 0x752dd6408ea0> of the transform datasets.arrow_dataset.Dataset._map_single couldn't be hashed properly, a random hash was used instead. Make sure your transforms and parameters are serializable with pickle or dill for the dataset fingerprinting and caching to work. If you reuse this transform, the caching mechanism will consider it to be different from the previous calls and recompute everything. This warning is only showed once. Subsequent hashing failures won't be showed.\n",
      "Map:  25%|██▌       | 25/100 [02:37<07:45,  6.21s/ examples]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-23 15:55:09.935\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_incorrect_solutions\u001b[0m:\u001b[36m23\u001b[0m - \u001b[33m\u001b[1m['control_gd_removed'] is ignored.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map:  26%|██▌       | 26/100 [04:23<24:33, 19.91s/ examples]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-10-23 15:56:56.101\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mcreate_incorrect_solutions\u001b[0m:\u001b[36m23\u001b[0m - \u001b[33m\u001b[1m['control_gsr_inverted'] is ignored.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 100/100 [18:22<00:00, 11.03s/ examples]\n"
     ]
    }
   ],
   "source": [
    "expanded_ds_inc = ds.map(create_incorrect_solutions,batched=True,batch_size=1,load_from_cache_file=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3939a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset,concatenate_datasets\n",
    "generated_ds:Dataset = concatenate_datasets([expanded_ds_cor,expanded_ds_inc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e93be38a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5491"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(generated_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "972196b8",
   "metadata": {},
   "source": [
    "#### Filtering the ones that do not compile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8c5b9db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from vif.utils.renderer.tex_renderer import TexRenderer\n",
    "\n",
    "\n",
    "renderer = TexRenderer()\n",
    "\n",
    "def renders(row):\n",
    "    try:\n",
    "        renderer.from_string_to_image(row[\"solution\"])\n",
    "        row[\"compiles\"]=True\n",
    "    except:\n",
    "        row[\"compiles\"]=False\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e4a5e2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 5491/5491 [41:37<00:00,  2.20 examples/s]  \n"
     ]
    }
   ],
   "source": [
    "compiling_generated = generated_ds.map(renders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2741d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "compiling_generated_pd = compiling_generated.to_pandas()\n",
    "compiling_generated_filtered = compiling_generated_pd[compiling_generated_pd[\"compiles\"]==True]\n",
    "not_compiling_generated_filtered = compiling_generated_pd[compiling_generated_pd[\"compiles\"]==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1736eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4112\n",
      "\\documentclass[tikz,border=5]{standalone}\n",
      "\\usepackage[prefix=]{xcolor-material}\n",
      "\n",
      "\\tikzset{\n",
      "  half clip/.code={\n",
      "    \\clip (0, -256) rectangle (256, 256);\n",
      "  },\n",
      "  color alias/.code args={#1 as #2}{\\colorlet{#1}{#2}},\n",
      "  colors alias/.style={color alias/.list/.expanded={#1}},\n",
      "  execute/.code={#1},\n",
      "  on left/.style={.. on left/.style={#1}},\n",
      "  on right/.style={.. on right/.style={#1}},\n",
      "}\n",
      "\\newcommand\\reflect[2][]{\n",
      "\\begin{scope}[#1]\\foreach \\side in {-1, 1}{\\begin{scope}\n",
      "\\ifnum\\side=-1 \\tikzset{.. on left/.try}\\else\\tikzset{.. on right/.try}\\fi\n",
      "\\begin{scope}[xscale=\\side]#2\\end{scope}\n",
      "\\end{scope}}\\end{scope}}\n",
      "\n",
      "\n",
      "\\tikzset{\n",
      "bee/.pic={\n",
      "\\begin{scope}[x=3cm/480,y=3cm/480, rotate=-45, shift=(270:48)]\n",
      "\\reflect[\n",
      "  on left= {colors alias={body as BlueGrey800, stripes as Amber500}},\n",
      "  on right={colors alias={body as BlueGrey900, stripes as Amber700}, half clip},\n",
      "  lower wing/.style={fill=BlueGrey100}, upper wing/.style={fill=BlueGrey50}]{\n",
      "  \\fill [body] (0,-160)\n",
      "    .. controls ++(120:64) and ++(270:64) .. (-88, -16)\n",
      "    .. controls ++( 90:64) and ++(225:64) .. (  0, 128)\n",
      "    .. controls ++(315:64) and ++( 90:64) .. ( 88, -16)\n",
      "    .. controls ++(270:64) and ++( 60:64) .. cycle;\n",
      "  \\fill [body] (0,128) ellipse [x radius=80, y radius=56];\n",
      "  \\fill [body]\n",
      "    (32,160) arc (180:90:64) -- ++(6,-6) coordinate [midway] (@)\n",
      "    arc (90:180:64) -- cycle;\n",
      "  \\fill [body] (@) circle [radius=12];\n",
      "  \\begin{scope}\n",
      "    \\clip (0,-160)\n",
      "      .. controls ++(120:64) and ++(270:64) .. (-88, -16)\n",
      "      .. controls ++( 90:64) and ++(225:64) .. (  0, 128)\n",
      "      .. controls ++(315:64) and ++( 90:64) .. ( 88, -16)\n",
      "      .. controls ++(270:64) and ++( 60:64) .. cycle;\n",
      "    \\foreach \\i in {0,...,2}\n",
      "      \\fill [stripes] (-256, -160 + \\i*80) rectangle ++(512, 40);\n",
      "  \\end{scope}\n",
      "  \\foreach \\s [count=\\i from -1] in {lower wing, upper wing}\n",
      "    \\fill [style=\\s, shift={(16,56)}, rotate=\\i*32]\n",
      "      (0,0)\n",
      "      .. controls ++( 30:64) and ++(180:32) .. (128,56)\n",
      "      arc (90:-90:56)\n",
      "      .. controls ++(180:32) and ++(330:64) .. cycle;\n",
      "  \\fill [BlueGrey100] (50, §rangei(150,5)) circle [radius=§rangei(20,713BlueGrey700] (§rangei(40,1300,155dius=§rangei(7,5)];\n",
      "    \n",
      "}\n",
      "\\end{scope}}\n",
      "}\n",
      "\\begin{do2in{tikzpicture}\n",
      "\\fill [fill=LightBlue300] circle [radius=2];\n",
      "\\pic {bee};\n",
      "\\end{tikzpicture}\n",
      "\\end{document}\n"
     ]
    }
   ],
   "source": [
    "print(len(not_compiling_generated_filtered))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dedbbaa",
   "metadata": {},
   "source": [
    "#### Removing duplicate ones(If Any)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2d2c73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "compiling_dedup_pd = compiling_generated_filtered.drop_duplicates(\"solution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa7a43e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5491\n",
      "5491\n",
      "1379\n"
     ]
    }
   ],
   "source": [
    "print(len(generated_ds))\n",
    "print(len(compiling_generated))\n",
    "print(len(compiling_dedup_pd))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c88dc1",
   "metadata": {},
   "source": [
    "#### Creating a 50/50 ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d814bf74",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_203149/2521951183.py:3: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  dedup_50 = compiling_dedup_pd.groupby(\"id\",group_keys=False).apply(lambda g: pd.concat([\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dedup_50 = compiling_dedup_pd.groupby(\"id\",group_keys=False).apply(lambda g: pd.concat([\n",
    "          g[g['expected']].head(5),\n",
    "          g[~g['expected']].head(5)\n",
    "      ])).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2edfa1ae",
   "metadata": {},
   "source": [
    "#### Publishing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61ab739",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating parquet from Arrow format: 100%|██████████| 1/1 [00:00<00:00, 584.25ba/s]\n",
      "Uploading the dataset shards: 100%|██████████| 1/1 [00:02<00:00,  2.08s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/datasets/CharlyR/VeriTikz/commit/e2a07ed733722f4cd1dc92847212f531d068bb58', commit_message='Upload dataset', commit_description='', oid='e2a07ed733722f4cd1dc92847212f531d068bb58', pr_url=None, repo_url=RepoUrl('https://huggingface.co/datasets/CharlyR/VeriTikz', endpoint='https://huggingface.co', repo_type='dataset', repo_id='CharlyR/VeriTikz'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we'll see later about that\n",
    "Dataset.from_pandas(dedup_50)\n",
    "ds.push_to_hub(\"CharlyR/VeriTikz\", config_name=\"raw\", split=\"train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0642630",
   "metadata": {},
   "source": [
    "#### Dataset statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ac7cb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e105b1f2",
   "metadata": {},
   "source": [
    "### some tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd5a8e19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\\\documentclass[tikz,border=5]{standalone}\\n\\\\usepackage{tikz}\\n\\\\usetikzlibrary{\\n                arrows.meta,\\n                bending,\\n                positioning\\n               }\\n\\\\tikzset{\\n         > = Latex,\\n         arrows = {[bend]},\\n         signal/.style = coordinate,\\n         sum/.style = {\\n                       draw,\\n                       circle,\\n                       minimum size = 2mm\\n                      },\\n         block/.style = {\\n                         draw,\\n                         rectangle,\\n                         minimum height = 2em,\\n                         minimum width = 4em\\n                        },\\n         branch/.style = {\\n                          sum,\\n                          minimum size = 1mm,\\n                          fill = black\\n                         }\\n        }\\n\\n\\\\begin{document}\\n\\n  \\\\begin{tikzpicture}[auto]\\n\\n    \\\\node[signal] (input) {};\\n    \\\\node[sum, right = of input] (left sum) {};\\n    \\\\node[block, right = of left sum] (controller) {$G_R$};\\n    \\\\node[block, right = of controller] (system) {$G_S$};\\n    \\\\draw\\n      [->] (controller) -- node[name = u] {$U$} (system);\\n    \\\\node[block, above = of system] (dynamic of disturbances) {$G_D$};\\n    \\\\node[signal, left = of dynamic of disturbances] (disturbances) {};\\n    \\\\node[sum, right = of system] (right sum) {};\\n    \\\\node[branch, right = of right sum] (branch) {};\\n    \\\\node[signal, right = of branch] (output) {};\\n    \\\\node[sum, below = of branch] (lower sum) {};\\n    \\\\node[signal, right = of lower sum] (measurement noise) {};\\n    \\\\node[block] (measurement) at (u |- lower sum) {$G_M$};\\n    \\\\draw\\n      [->] (input) -- node {$W$} (left sum);\\n    \\\\draw\\n      [->] (left sum) -- node {$E$} (controller);\\n    \\\\draw\\n      [->] (system) -- (right sum);\\n    \\\\draw\\n      [->] (disturbances) -- node {$Z$} (dynamic of disturbances);\\n    \\\\draw\\n      [->] (dynamic of disturbances) -| (right sum);\\n    \\\\draw\\n      (right sum) -- (branch);\\n    \\\\draw\\n      [->] (branch) -- node {$Y$} (output);\\n    \\\\draw\\n      [->] (branch) -- (lower sum);\\n    \\\\draw\\n      [->] (measurement noise) -- node[above] {$M$} (lower sum);\\n    \\\\draw\\n      [->] (lower sum) -- (measurement);\\n    \\\\draw\\n      [->] (measurement) -| node[pos = .95] {$-$} (left sum);\\n\\n  \\\\end{tikzpicture}\\n\\n\\n\\n\\\\end{document}'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_row_code = ds.select([24])[\"template_solution_code\"][0][0]\n",
    "original_test_row_code = ds.select([25])[\"code\"][0]\n",
    "original_test_row_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccd5b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_all_incorrect_solutions(original_test_row_code,test_row_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53c573b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_row = ds.select(range(24,100))\n",
    "hu=test_row.map(create_incorrect_solutions,batched=True,batch_size=1,load_from_cache_file=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a07237e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "VIFagent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
